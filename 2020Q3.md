0920
- ML: 최소제곱오차를 다시 살펴봄. 예측치가 한 값이 아니라 정의역에 따라 각 치역의 예측값으로 보이는데 복습하기 전에는 이게 정의역 무관한 단일값이라고 생각하고 있었음 (왜지?)
- 0916~0919 총 4일 동안 학습 마인드셋을 구조적으로 다시 다잡음. 기존 마인드셋이 허점이 있었음. * 구조적이라고 말하는 이유는 특정한 전제들 위에 마인드셋을 잡았기 때문. (상세내역은 TIL에서 적을 내용은 아님)

0916
- ML: ML 다루는 회사들 직원 소감(?) 인터뷰들을 시청

0915
- ML: Sung kim님의 강의를 들어보니 며칠간 책으로 읽었던 내용이 비로소 이해가 되기 시작.
  - 일반적인 프로그래밍은 explicit 프로그래밍, 명확하고 많은 rule들의 로직인데, ML은 explicit rule을 통한 엔지니어링을 하기에는 너무 복잡한 것들에 쓰이는 것을 가정한다 (이미 1950년대 말에 논문이 나옴)
  - 일차함수 기준 MSE는 예측선인 Hypothesis와 실제값 사이의 차의 제곱을 변수 분포의 개수로 나누어준 값이고, 이 값을 최소화하는 기울기와 절편 값을 찾는 것 --> regression
  - 최소제곱법으로 기울기를 구하는 부분은 아직 잘 이해가 가지 않는다. 변수가 여러개일 때의 최소제곱법도 아직 잘 이해는 가지 않는다.

0914
- 모두의 딥러닝: 경사하강법 -> 오류값을 최소로 줄이기 위해 미분값이 0이 되는 지점에 가까워지도록 학습률을 조정한다. 평균제곱오차로 만든 이차함수를 그 기울기와 절편에 대해서 편미분해주고, 그 값을 학습률과 곱해서 다음 루프에서 다시 계산. 근데 계산을 거듭할 수록 왜 값이 수렴하는지 정확히 이해하지 못함

0913
- '소양'에 대한 생각(추후 다른 글에서 정리)
- 모두의 딥러닝: MSE를 수학적으로 어느정도 이해했는데 프로그래밍적으로는 시그마해주는 부분에서 이해가 안가는게 있음
- 빅데이터를 지탱하는 기술: 책에 따르면 데이터량의 폭증으로 RDB의 한계가 생기자, 이를 극복하기 위해 하둡과 NOSQL이 나왔다고 함.
  - SQL 같은 쿼리 언어로 하둡을 이용하고자 하이브 소프트웨어가 생겼고,
  - 하둡에서 말하는 분산처리가 무엇일까? (하둡이 다수의 컴퓨터에서 대량의 데이터를 처리할 목적이라며느 분산한다는게 컴퓨터를 분산해서 계산한다는 건가?)
  - NOSQL 스토리지의 종류: 키-밸류 / 도큐먼트 / 와이드 칼럼 : 이 가운데 와이드 칼럼에 카산드라가 있다는 것을 이제야 알게 됨.

0912
- 머신러닝 기초 수학 복습
  - 수학을 보는 눈이 조금 달라진듯
    - 정의 그 자체보다, 정의가 어떤 의미가 있는지를 판단해보게됨 (<-- 개념적으로, 또는 수학 자체적으로, 또는 공학적인 활용도 측면에서) 
  - 일차함수:
    - 기울기: x의 값이 증가할 때 y 값은 얼마나 증가할까? --> x의 값이 증가할 때 y 값이 어느정도 증가하는지를 값으로 나타냄 --> x의 변화량에 대한 y의 변화량
    - 절편: 그래프(선)가 축과 만나는 지점 --> 예를 들어, y 절편은 y축과 그래프가 만날 때의 y 값
  - 미분:
    - 미분한다 --> 순간변화율을 구한다
      - 미분계수 --> 어떤 점에서의 평균 변화율의 극한(=어떤 점에서의 순간변화율과 같은 말인듯) --> 도함수의 함수값
    - 순간변화율 --> x가 0에 가까울 만큼 작게 변할 때 y의 변화량은 실제 값의 변화는 매우 미세하고 방향성만 표현되는 정도일 것, 이 순간의 변화율이 순간변화율
      - 순간변화율의 방향대로 그어지는 직선이 그 점에서의 기울기
  - 지수함수는 어떤 값을 거듭제곱한 결과값을 함수값으로하는 함수이고, 로그함수는 거듭제곱 값 자체를 함수값으로 하는 함수 (역함수 관계)
  - 시그모이드함수
    - { 1 / (1 + e^(-x) )}
    - 분모에 자연상수의 거듭제곱값을 변수로 해서, 거듭제곱값이 0보다 작으면 거듭제곱된 결과값이 커지니까 함수값이 점점 작아지고, 0보다 크면 거듭제곱된 값이 점점 0에 가까워지면서 함수값이 커지며 점점 1에 가까워진다 

0911
- tensorflow 처음 설치, 길벗IT의 '나의 첫번째 딥러닝' 책으로부터 생존율 예측 실습해봄
- 학습한 데이터가 적절했나? 양은 충분했나? 노이즈는 얼마나 있을까? / 학습 방법은 적절했나? ...

0910
- 평균제곱오차: 오차를 파악할 때 부호 구분 없이 오차량을 절대값으로 파악하기 위해서 제곱을 활용. 1/n(sum((y'(i)-y(i)))^2) = mean(sum(sqrt(predict(i)-actual(i))))

0909
- 최소제곱: 프로그래밍적인 구현

0908
- 확률 기초 책 보면서, 확률에 대한 기초 이해. (복습이지만 새로운 멘탈모델로 접근해서,,).
- 키워드: 도수분포, 추출, 유의 상관, 떨어진 정도, 표준편차, 정규분포, t-value, 독립성 검정
